{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes_Seq_1.2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carvalheirafc/deep_learning_stuff/blob/master/neural_networks/diabetes/task3/diabetes_Seq_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eY1zeuTc9xVy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# WWWMMMWWMMWM\n"
      ]
    },
    {
      "metadata": {
        "id": "NKsfFlql9w8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow.keras.metrics as metrics\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwDcJXbq-VhQ",
        "colab_type": "code",
        "outputId": "d29c7229-3b91-4adc-bf72-ed6a699a3bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "data_url = 'https://raw.githubusercontent.com/carvalheirafc/deep_learning_stuff/master/neural_networks/diabetes/diabetes_pca_result.csv'\n",
        "\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "features = df.drop('Diagnóstico', axis = 1)\n",
        "target = df['Diagnóstico']\n",
        "\n",
        "\n",
        "print('Data Shape:', features.shape)\n",
        "print('Labels/Target:', target.shape)\n",
        "df.describe().transpose()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (768, 4)\n",
            "Labels/Target: (768,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Component 1</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-6.693141e-17</td>\n",
              "      <td>1.711960</td>\n",
              "      <td>-5.587340</td>\n",
              "      <td>-1.027072</td>\n",
              "      <td>0.152931</td>\n",
              "      <td>1.095689</td>\n",
              "      <td>5.963579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 2</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-6.071532e-17</td>\n",
              "      <td>1.318184</td>\n",
              "      <td>-2.955806</td>\n",
              "      <td>-1.007096</td>\n",
              "      <td>-0.225966</td>\n",
              "      <td>0.959128</td>\n",
              "      <td>3.606582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 3</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-3.324887e-17</td>\n",
              "      <td>1.015629</td>\n",
              "      <td>-3.203088</td>\n",
              "      <td>-0.646496</td>\n",
              "      <td>-0.103940</td>\n",
              "      <td>0.549774</td>\n",
              "      <td>4.754503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 4</th>\n",
              "      <td>768.0</td>\n",
              "      <td>2.349105e-18</td>\n",
              "      <td>0.966941</td>\n",
              "      <td>-2.192185</td>\n",
              "      <td>-0.664677</td>\n",
              "      <td>-0.115829</td>\n",
              "      <td>0.543242</td>\n",
              "      <td>4.125987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diagnóstico</th>\n",
              "      <td>768.0</td>\n",
              "      <td>3.489583e-01</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             count          mean       std       min       25%       50%  \\\n",
              "Component 1  768.0 -6.693141e-17  1.711960 -5.587340 -1.027072  0.152931   \n",
              "Component 2  768.0 -6.071532e-17  1.318184 -2.955806 -1.007096 -0.225966   \n",
              "Component 3  768.0 -3.324887e-17  1.015629 -3.203088 -0.646496 -0.103940   \n",
              "Component 4  768.0  2.349105e-18  0.966941 -2.192185 -0.664677 -0.115829   \n",
              "Diagnóstico  768.0  3.489583e-01  0.476951  0.000000  0.000000  0.000000   \n",
              "\n",
              "                  75%       max  \n",
              "Component 1  1.095689  5.963579  \n",
              "Component 2  0.959128  3.606582  \n",
              "Component 3  0.549774  4.754503  \n",
              "Component 4  0.543242  4.125987  \n",
              "Diagnóstico  1.000000  1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "2ECD_bV_A7uD",
        "colab_type": "code",
        "outputId": "7b422af7-7cd6-4c05-e29c-2ead2a4c8c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "network = Sequential()\n",
        "\n",
        "    \n",
        "network.add(Dense(units=32, activation='relu', input_shape=(features.shape[1],),\n",
        "                         kernel_initializer='random_uniform', \n",
        "                         bias_initializer='ones'))\n",
        "\n",
        "    \n",
        "network.add(Dense(units=32, activation='relu'))\n",
        "network.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tz2eOYdbEBce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_train(optimizer, seed, X, y):\n",
        "  k_fold = StratifiedKFold(n_splits=25, shuffle=True, random_state=seed)\n",
        "  cvscores = []\n",
        "  prediction_acc = []\n",
        "  \n",
        "  network.compile(loss='mse', optimizer=optimizer, metrics=['accuracy', 'mse'])\n",
        "  X_train = []\n",
        "  for train, test in k_fold.split(X, y):\n",
        "    X_train.append(X[train])\n",
        "    history = network.fit(X[train], y[train], epochs=200, batch_size=10, verbose=0)\n",
        "  \n",
        "    scores = network.evaluate(X[test], y[test], verbose=2)\n",
        "    prediction = network.predict(X[test])\n",
        "    \n",
        "    print(scores)\n",
        "    \n",
        "    prediction_acc.append((prediction, y[test]))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "  print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
        "  return history, prediction_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmNXc9gJIXWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features.values\n",
        "y = target.values\n",
        "\n",
        "seed = 666\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNFnt1l9pNvt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sgd_custom = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#model_train(sgd_custom, seed, X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bJ-EkmPbkW_",
        "colab_type": "code",
        "outputId": "fabc442f-0d7c-4742-8896-0f420c48f0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        }
      },
      "cell_type": "code",
      "source": [
        "adam_custom = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
        "adam_model_history, predictions = model_train(adam_custom, seed, X, y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " - 0s - loss: 0.1688 - acc: 0.7742 - mean_squared_error: 0.1688\n",
            "[0.1687716245651245, 0.7741935, 0.16877162]\n",
            " - 0s - loss: 0.2073 - acc: 0.6129 - mean_squared_error: 0.2073\n",
            "[0.20725108683109283, 0.61290324, 0.20725109]\n",
            " - 0s - loss: 0.1978 - acc: 0.6774 - mean_squared_error: 0.1978\n",
            "[0.19782160222530365, 0.67741936, 0.1978216]\n",
            " - 0s - loss: 0.1762 - acc: 0.7419 - mean_squared_error: 0.1762\n",
            "[0.17615236341953278, 0.7419355, 0.17615236]\n",
            " - 0s - loss: 0.1383 - acc: 0.7742 - mean_squared_error: 0.1383\n",
            "[0.1383136659860611, 0.7741935, 0.13831367]\n",
            " - 0s - loss: 0.1659 - acc: 0.7742 - mean_squared_error: 0.1659\n",
            "[0.16585104167461395, 0.7741935, 0.16585104]\n",
            " - 0s - loss: 0.0756 - acc: 0.8710 - mean_squared_error: 0.0756\n",
            "[0.07561211287975311, 0.87096775, 0.07561211]\n",
            " - 0s - loss: 0.1633 - acc: 0.7742 - mean_squared_error: 0.1633\n",
            "[0.16329054534435272, 0.7741935, 0.16329055]\n",
            " - 0s - loss: 0.1678 - acc: 0.7419 - mean_squared_error: 0.1678\n",
            "[0.16779382526874542, 0.7419355, 0.16779383]\n",
            " - 0s - loss: 0.1253 - acc: 0.8710 - mean_squared_error: 0.1253\n",
            "[0.1253218948841095, 0.87096775, 0.1253219]\n",
            " - 0s - loss: 0.0540 - acc: 0.9355 - mean_squared_error: 0.0540\n",
            "[0.0539623387157917, 0.9354839, 0.05396234]\n",
            " - 0s - loss: 0.0742 - acc: 0.9032 - mean_squared_error: 0.0742\n",
            "[0.07423856854438782, 0.9032258, 0.07423857]\n",
            " - 0s - loss: 0.0831 - acc: 0.9032 - mean_squared_error: 0.0831\n",
            "[0.08309177309274673, 0.9032258, 0.08309177]\n",
            " - 0s - loss: 0.0392 - acc: 0.9355 - mean_squared_error: 0.0392\n",
            "[0.0391770638525486, 0.9354839, 0.039177064]\n",
            " - 0s - loss: 0.0352 - acc: 0.9677 - mean_squared_error: 0.0352\n",
            "[0.03522253781557083, 0.9677419, 0.035222538]\n",
            " - 0s - loss: 0.0820 - acc: 0.9032 - mean_squared_error: 0.0820\n",
            "[0.08197931945323944, 0.9032258, 0.08197932]\n",
            " - 0s - loss: 0.0322 - acc: 0.9355 - mean_squared_error: 0.0322\n",
            "[0.03222455456852913, 0.9354839, 0.032224555]\n",
            " - 0s - loss: 0.0910 - acc: 0.8710 - mean_squared_error: 0.0910\n",
            "[0.09096545726060867, 0.87096775, 0.09096546]\n",
            " - 0s - loss: 0.0799 - acc: 0.9000 - mean_squared_error: 0.0799\n",
            "[0.07987471669912338, 0.9, 0.07987472]\n",
            " - 0s - loss: 0.0308 - acc: 0.9667 - mean_squared_error: 0.0308\n",
            "[0.030793866142630577, 0.96666664, 0.030793866]\n",
            " - 0s - loss: 0.0619 - acc: 0.9333 - mean_squared_error: 0.0619\n",
            "[0.061858970671892166, 0.93333334, 0.06185897]\n",
            " - 0s - loss: 0.0777 - acc: 0.9000 - mean_squared_error: 0.0777\n",
            "[0.07768283784389496, 0.9, 0.07768284]\n",
            " - 0s - loss: 0.0928 - acc: 0.8667 - mean_squared_error: 0.0928\n",
            "[0.09275054931640625, 0.8666667, 0.09275055]\n",
            " - 0s - loss: 0.1246 - acc: 0.8667 - mean_squared_error: 0.1246\n",
            "[0.12456383556127548, 0.8666667, 0.124563836]\n",
            " - 0s - loss: 0.0496 - acc: 0.9333 - mean_squared_error: 0.0496\n",
            "[0.049623824656009674, 0.93333334, 0.049623825]\n",
            "85.34% (+/- 9.18%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GVBCS4pI8y2T",
        "colab_type": "code",
        "outputId": "317a1c50-ef7e-45f4-a0ca-9f5896e22554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "score_df = pd.DataFrame(predictions)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'mean_squared_error'])\n",
            "dict_values([[0.03769785435280622, 0.03932664866260924, 0.0433378300769206, 0.04134908465977691, 0.03888482985390108, 0.0379305665232543, 0.036698897200827654, 0.03379687536341757, 0.03512283839022507, 0.03430958836867891, 0.035245897046474586, 0.03918242919799974, 0.03676646334677418, 0.03376950969710055, 0.0337395343682297, 0.037991845706474466, 0.03698870144450508, 0.04943541867530767, 0.04793295728734708, 0.0456162024233798, 0.04260388308243238, 0.03875097417866287, 0.039049594230794106, 0.039084962396428245, 0.04021179747566283, 0.04191515688671562, 0.04120880576154011, 0.04219526423150147, 0.04589302693292096, 0.04053694826666411, 0.04131531096754192, 0.039964637124167354, 0.039822400414479486, 0.03804064820389836, 0.039361788882802305, 0.04094133968023974, 0.04031865372562374, 0.05353702438681564, 0.045862344769725796, 0.04898055949098592, 0.04457350704440253, 0.042209537003982125, 0.04750722544387277, 0.04406295359497748, 0.04754428429167253, 0.043160302307216736, 0.04031297970274018, 0.04095695041001171, 0.04054224400045972, 0.04136563681127233, 0.040640608774454606, 0.04114644458120758, 0.040308614658128135, 0.03982262012030277, 0.04291939406013527, 0.04990049521811937, 0.051341886503930345, 0.042194488643574085, 0.04307818928834764, 0.04184517917196738, 0.044540773937854175, 0.041549616068059556, 0.03877702833537909, 0.03748290551644207, 0.03657998528203149, 0.04077766161143235, 0.042655398923341296, 0.03656033674298403, 0.035413245620359704, 0.032811823544395234, 0.03420194557975513, 0.03361985215842492, 0.03491569777620782, 0.033201885206249254, 0.035132496240592365, 0.03382674159329228, 0.03187290743911315, 0.03434726169462282, 0.03584488260334357, 0.03644955418665386, 0.036155868330853186, 0.03939123802731076, 0.037204784794109026, 0.04071490542840545, 0.03934190107171428, 0.03250134918810489, 0.03271391298776786, 0.03285788209810975, 0.032799179292067764, 0.03279405359500227, 0.03308031935838217, 0.032749369954205756, 0.03678947099787369, 0.03765543606984545, 0.03224646288437646, 0.033856287984183685, 0.03965778975140869, 0.03829210344788145, 0.04655245663415465, 0.04146834027099043, 0.041123703216858265, 0.045407495386818125, 0.04436852927192209, 0.04716775566156267, 0.040348824522424546, 0.0397526094289636, 0.03553255464748626, 0.03974017925062382, 0.03530325333791391, 0.03475586208689561, 0.03209902073457006, 0.03314320137807127, 0.032433948107780615, 0.03438415721592715, 0.03413402826027099, 0.0320150131617837, 0.031917400378528804, 0.035084399980452256, 0.0376227667250068, 0.03182577127589138, 0.0322922552634257, 0.03250776923253676, 0.03363296754372271, 0.03172654404055932, 0.033781108679186725, 0.035695056124900815, 0.034960925525078235, 0.045671772546470694, 0.03727876616547457, 0.0401543375053002, 0.037034147643150085, 0.035393894786712427, 0.04222056208641993, 0.038082173990924076, 0.0399142131720878, 0.03838143988734501, 0.03771801930945435, 0.03538594155223819, 0.03941265714483735, 0.04390258404244203, 0.03393917450309656, 0.03233842346838193, 0.036697716819747525, 0.034486094466590476, 0.031794343361334826, 0.03390078121465066, 0.03450821192594413, 0.03370606124915375, 0.03633675910260689, 0.04023620297961457, 0.03947472621320744, 0.03480609494684201, 0.033840150201861104, 0.032645450862959655, 0.03681367353362406, 0.040908724390469546, 0.03593292107530853, 0.03278924784644717, 0.03430049697709974, 0.033535138081897266, 0.032520321820842316, 0.03629524571896227, 0.032383614640274984, 0.032381760434252053, 0.03341445150212674, 0.03701725463380185, 0.03525867287476904, 0.04392123095534023, 0.04494414590077902, 0.04718350184806429, 0.052375745554365166, 0.04540699559485437, 0.03782915022840086, 0.034073520620210775, 0.03411618667145473, 0.03566361380541794, 0.03217163006896193, 0.032807839104325984, 0.032291518378741405, 0.03477573347011946, 0.03296695556945752, 0.03344141654942348, 0.03442963596327239, 0.032030172553165086, 0.03371951102557679, 0.0331515049295808, 0.033283984466694345, 0.03283452255166213, 0.0329449802236327, 0.03160380366626441, 0.04373236322319782, 0.042231277194534, 0.046926968026272185, 0.04238211589599788, 0.04189575358925983, 0.038395904201755475, 0.03606327053109926, 0.03509114500952601, 0.034404732500585435, 0.03604666116594759], [0.9634146, 0.9593496, 0.95257455, 0.9512195, 0.95528454, 0.9593496, 0.9634146, 0.96747965, 0.96476966, 0.96476966, 0.9634146, 0.9579946, 0.9634146, 0.96747965, 0.9688347, 0.9593496, 0.9634146, 0.94579947, 0.9498645, 0.95528454, 0.9579946, 0.9620596, 0.9607046, 0.9620596, 0.9607046, 0.9579946, 0.9593496, 0.9566396, 0.9512195, 0.9593496, 0.9634146, 0.9579946, 0.9607046, 0.9620596, 0.9620596, 0.9566396, 0.9579946, 0.94173443, 0.95257455, 0.94715446, 0.9566396, 0.9566396, 0.94715446, 0.9566396, 0.9512195, 0.95528454, 0.9579946, 0.9579946, 0.9607046, 0.9579946, 0.9593496, 0.9579946, 0.9593496, 0.9620596, 0.9566396, 0.94579947, 0.9444444, 0.95528454, 0.9566396, 0.95528454, 0.94579947, 0.9512195, 0.9607046, 0.9620596, 0.9634146, 0.9593496, 0.9566396, 0.96476966, 0.9593496, 0.96747965, 0.96612465, 0.9634146, 0.9620596, 0.96476966, 0.9634146, 0.96476966, 0.96747965, 0.96476966, 0.9620596, 0.9566396, 0.9634146, 0.95528454, 0.9634146, 0.95257455, 0.9579946, 0.9688347, 0.96747965, 0.96612465, 0.9688347, 0.9688347, 0.96612465, 0.9701897, 0.96476966, 0.9620596, 0.9688347, 0.96612465, 0.95528454, 0.9620596, 0.95257455, 0.9579946, 0.95528454, 0.9498645, 0.9485095, 0.9512195, 0.9566396, 0.9566396, 0.96476966, 0.95528454, 0.96612465, 0.96747965, 0.9701897, 0.96747965, 0.96747965, 0.9634146, 0.96747965, 0.9688347, 0.9688347, 0.96476966, 0.9607046, 0.9688347, 0.9701897, 0.96747965, 0.9688347, 0.97154474, 0.96476966, 0.9620596, 0.9634146, 0.9498645, 0.96476966, 0.95528454, 0.9593496, 0.9593496, 0.95257455, 0.9620596, 0.9579946, 0.9607046, 0.9634146, 0.96612465, 0.9579946, 0.94715446, 0.9634146, 0.9688347, 0.96612465, 0.96476966, 0.9701897, 0.9634146, 0.96612465, 0.96476966, 0.9620596, 0.9579946, 0.9579946, 0.96612465, 0.9634146, 0.9688347, 0.9607046, 0.95528454, 0.96476966, 0.96747965, 0.96747965, 0.96747965, 0.9688347, 0.9579946, 0.97154474, 0.9701897, 0.96747965, 0.9579946, 0.96476966, 0.9512195, 0.94715446, 0.94715446, 0.9403794, 0.9498645, 0.9593496, 0.96612465, 0.96612465, 0.9607046, 0.9688347, 0.96747965, 0.9688347, 0.96476966, 0.96612465, 0.96747965, 0.9620596, 0.9688347, 0.96476966, 0.96747965, 0.96612465, 0.96612465, 0.96747965, 0.9688347, 0.95392954, 0.9566396, 0.9444444, 0.9512195, 0.9566396, 0.9607046, 0.9620596, 0.96476966, 0.9634146, 0.9607046], [0.03769785, 0.039326645, 0.04333783, 0.041349083, 0.038884833, 0.03793057, 0.0366989, 0.033796877, 0.03512284, 0.034309585, 0.035245903, 0.039182432, 0.03676647, 0.03376951, 0.033739537, 0.037991844, 0.0369887, 0.049435426, 0.047932953, 0.045616202, 0.042603884, 0.03875097, 0.039049596, 0.039084964, 0.040211793, 0.04191516, 0.041208807, 0.04219526, 0.04589302, 0.040536936, 0.04131531, 0.03996464, 0.039822396, 0.038040645, 0.039361786, 0.040941335, 0.04031866, 0.053537033, 0.045862343, 0.048980556, 0.04457351, 0.042209543, 0.047507223, 0.044062946, 0.047544282, 0.0431603, 0.04031298, 0.04095695, 0.040542245, 0.04136564, 0.040640607, 0.041146446, 0.04030861, 0.039822623, 0.0429194, 0.049900495, 0.051341895, 0.04219449, 0.043078195, 0.041845176, 0.044540767, 0.041549627, 0.038777024, 0.0374829, 0.03657998, 0.04077766, 0.04265539, 0.036560338, 0.035413247, 0.03281182, 0.034201942, 0.03361986, 0.0349157, 0.033201884, 0.0351325, 0.033826742, 0.031872913, 0.034347262, 0.035844892, 0.03644955, 0.03615586, 0.039391235, 0.03720479, 0.0407149, 0.0393419, 0.03250135, 0.03271392, 0.03285788, 0.032799173, 0.03279405, 0.033080313, 0.032749366, 0.036789473, 0.037655428, 0.03224646, 0.033856284, 0.03965779, 0.038292103, 0.046552457, 0.041468337, 0.041123696, 0.045407493, 0.044368528, 0.04716775, 0.040348824, 0.0397526, 0.035532556, 0.039740186, 0.035303254, 0.034755863, 0.03209902, 0.0331432, 0.032433953, 0.034384158, 0.034134027, 0.032015007, 0.031917404, 0.035084393, 0.037622765, 0.031825762, 0.03229225, 0.032507766, 0.033632968, 0.031726547, 0.03378111, 0.035695065, 0.03496093, 0.04567178, 0.037278768, 0.04015434, 0.037034154, 0.035393894, 0.04222055, 0.038082164, 0.039914213, 0.03838144, 0.037718017, 0.035385944, 0.039412662, 0.04390259, 0.03393917, 0.032338418, 0.036697723, 0.034486093, 0.031794343, 0.03390078, 0.034508217, 0.03370606, 0.03633677, 0.04023621, 0.039474722, 0.034806088, 0.033840153, 0.03264545, 0.036813673, 0.040908724, 0.035932917, 0.032789245, 0.034300502, 0.033535134, 0.032520324, 0.036295235, 0.032383613, 0.03238176, 0.033414453, 0.037017252, 0.035258677, 0.043921236, 0.04494415, 0.047183506, 0.052375738, 0.045406982, 0.037829153, 0.034073524, 0.034116182, 0.035663627, 0.03217163, 0.032807834, 0.032291517, 0.034775734, 0.032966956, 0.03344142, 0.03442964, 0.03203016, 0.03371951, 0.033151504, 0.033283975, 0.032834526, 0.03294499, 0.031603802, 0.04373236, 0.042231277, 0.046926964, 0.04238212, 0.04189575, 0.03839591, 0.036063273, 0.03509115, 0.034404732, 0.036046658]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYiPDIHxTw31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "daf1d4be-c07b-4aba-9500-c62bf9ba189f"
      },
      "cell_type": "code",
      "source": [
        "d = {'Resposta': predictions[1][0].reshape, 'Target': predictions[1][1]}\n",
        "d\n",
        "#df = pd.DataFrame(data=d)\n",
        "#df.head()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a629c659419b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Resposta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df = pd.DataFrame(data=d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 31 into shape (1,)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IQpPlwCOVaE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}