{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config) \n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "  @staticmethod\n",
    "  def build(n_channels, \n",
    "            rows, \n",
    "            cols, \n",
    "            n_classes, \n",
    "            activation='relu', \n",
    "            weights_path=None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    input_Shape = (rows, cols, n_channels)\n",
    "    \n",
    "   \n",
    "    #Convolution and Pooling Layers\n",
    "    model.add(Conv2D(20, kernel_size=5, activation=activation, input_shape=input_Shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(50, kernel_size=5, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #Flatten and Fully Conected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(activation))\n",
    "    \n",
    "    # OutputLayer SOFTMAX activation\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # if a weights path is supplied (inicating that the model was\n",
    "    # pre-trained), then load the weights\n",
    "    if weights_path is not None:\n",
    "      model.load_weights(weights_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "ini_learning_rate = 1e-3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14649/14649 [==============================] - 4s 248us/step - loss: 0.6909 - categorical_accuracy: 0.8057\n",
      "Epoch 2/10\n",
      "14649/14649 [==============================] - 2s 138us/step - loss: 0.1907 - categorical_accuracy: 0.9470\n",
      "Epoch 3/10\n",
      "14649/14649 [==============================] - 2s 138us/step - loss: 0.1455 - categorical_accuracy: 0.9590\n",
      "Epoch 4/10\n",
      "14649/14649 [==============================] - 2s 138us/step - loss: 0.1144 - categorical_accuracy: 0.9690\n",
      "Epoch 5/10\n",
      "14649/14649 [==============================] - 2s 139us/step - loss: 0.1054 - categorical_accuracy: 0.9721\n",
      "Epoch 6/10\n",
      "14649/14649 [==============================] - 2s 138us/step - loss: 0.0918 - categorical_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "14649/14649 [==============================] - 2s 145us/step - loss: 0.0889 - categorical_accuracy: 0.9771\n",
      "Epoch 8/10\n",
      "14649/14649 [==============================] - 2s 147us/step - loss: 0.0681 - categorical_accuracy: 0.9814\n",
      "Epoch 9/10\n",
      "14649/14649 [==============================] - 2s 144us/step - loss: 0.0545 - categorical_accuracy: 0.9846\n",
      "Epoch 10/10\n",
      "14649/14649 [==============================] - 2s 143us/step - loss: 0.0541 - categorical_accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_model = LeNet.build(n_channels=1, \n",
    "                              rows=28,\n",
    "                              cols=28, \n",
    "                              n_classes=26, \n",
    "                              activation='relu', \n",
    "                              weights_path=None)\n",
    "\n",
    "    opt = Adam(lr=ini_learning_rate, decay=ini_learning_rate / n_epochs)\n",
    "    train_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[categorical_accuracy])\n",
    "    try:\n",
    "        file_path = 'victor_weights_Letras.h5'\n",
    "        check_point = ModelCheckpoint(file_path, \n",
    "                                      monitor='categorical_accuracy', \n",
    "                                      verbose=0, \n",
    "                                      save_best_only=True,\n",
    "                                      mode='max',\n",
    "                                      save_weights_only=True)\n",
    "        callbacks_list = [check_point]\n",
    "        \n",
    "        train_history = train_model.fit(x=x_train, \n",
    "                                        y=y_train, \n",
    "                                        batch_size=batch_size, \n",
    "                                        epochs=n_epochs,\n",
    "                                        callbacks=callbacks_list,\n",
    "                                        verbose=1)\n",
    "    \n",
    "   \n",
    "    except IOError:\n",
    "        print('Error while saving the Model weights')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_history.history, open('history/victor', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
