{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "le_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carvalheirafc/deep_learning_stuff/blob/master/neural_networks/le_net/le_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htyq6krzTkip",
        "colab_type": "text"
      },
      "source": [
        "## Import Section\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxyYVKgGtUZH",
        "colab": {},
        "outputId": "6ab71204-1fd7-4ea3-ba4f-5b9b39281dee"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras import backend\n",
        "#from google.colab import drive\n",
        "from imutils import paths\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MY8JLHdpvUDA"
      },
      "source": [
        "## LeNet Class Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WObRC7NqhL2z",
        "colab": {}
      },
      "source": [
        "class LeNet:\n",
        "  @staticmethod\n",
        "  def build(n_channels, \n",
        "            rows, \n",
        "            cols, \n",
        "            n_classes, \n",
        "            activation='relu', \n",
        "            weights_path=None):\n",
        "    model = Sequential()\n",
        "    \n",
        "    input_Shape = (rows, cols, n_channels)\n",
        "    \n",
        "    # Convolution >> Activation >> Pool of Layers\n",
        "    model.add(Conv2D(20, 5, padding='same', input_shape=input_Shape))\n",
        "    model.add(Conv2D(20, kernel_size=5, activation=activation, input_shape=(rows, cols, n_channels)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(50, 5, activation=activation))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500))\n",
        "    model.add(Activation(activation))\n",
        "    \n",
        "    model.add(Dense(n_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    # if a weights path is supplied (inicating that the model was\n",
        "    # pre-trained), then load the weights\n",
        "    if weights_path is not None:\n",
        "      model.load_weights(weights_path)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kE_ez5oZqMSm"
      },
      "source": [
        "## Reading or Import Image Files.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6-pho9GqKg1",
        "colab": {}
      },
      "source": [
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQYZCiZVrvJs",
        "colab": {},
        "outputId": "06009f0a-206f-4a53-de66-e98819197bf9"
      },
      "source": [
        "root_path = 'Letras/'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "all_images_paths = sorted(list(paths.list_images(root_path)))\n",
        "current = -1\n",
        "\n",
        "try:\n",
        "    for image_path in all_images_paths:\n",
        "    \n",
        "    \n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = img_to_array(image)\n",
        "        data.append(image)\n",
        "    \n",
        "        label = image_path.split(os.path.sep)[-2][7:]\n",
        "        label = int(label)\n",
        "        labels.append(label)\n",
        "    \n",
        "        if current != label:\n",
        "            print('Loading Files into arrays...')\n",
        "            print('Loading Class [{}]'.format(label))\n",
        "        current = label\n",
        "\n",
        "    print('All Files are Loaded Successfully...')\n",
        "\n",
        "except IOError:\n",
        "    print('Something went Wrong loading the files')    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Files into arrays...\n",
            "Loading Class [0]\n",
            "Loading Files into arrays...\n",
            "Loading Class [10]\n",
            "Loading Files into arrays...\n",
            "Loading Class [11]\n",
            "Loading Files into arrays...\n",
            "Loading Class [12]\n",
            "Loading Files into arrays...\n",
            "Loading Class [13]\n",
            "Loading Files into arrays...\n",
            "Loading Class [14]\n",
            "Loading Files into arrays...\n",
            "Loading Class [15]\n",
            "Loading Files into arrays...\n",
            "Loading Class [16]\n",
            "Loading Files into arrays...\n",
            "Loading Class [17]\n",
            "Loading Files into arrays...\n",
            "Loading Class [18]\n",
            "Loading Files into arrays...\n",
            "Loading Class [19]\n",
            "Loading Files into arrays...\n",
            "Loading Class [1]\n",
            "Loading Files into arrays...\n",
            "Loading Class [20]\n",
            "Loading Files into arrays...\n",
            "Loading Class [21]\n",
            "Loading Files into arrays...\n",
            "Loading Class [22]\n",
            "Loading Files into arrays...\n",
            "Loading Class [23]\n",
            "Loading Files into arrays...\n",
            "Loading Class [24]\n",
            "Loading Files into arrays...\n",
            "Loading Class [25]\n",
            "Loading Files into arrays...\n",
            "Loading Class [2]\n",
            "Loading Files into arrays...\n",
            "Loading Class [3]\n",
            "Loading Files into arrays...\n",
            "Loading Class [4]\n",
            "Loading Files into arrays...\n",
            "Loading Class [5]\n",
            "Loading Files into arrays...\n",
            "Loading Class [6]\n",
            "Loading Files into arrays...\n",
            "Loading Class [7]\n",
            "Loading Files into arrays...\n",
            "Loading Class [8]\n",
            "Loading Files into arrays...\n",
            "Loading Class [9]\n",
            "All Files are Loaded Successfully...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Ii5CSETgEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_files = False\n",
        "\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "if save_files:\n",
        "    try:\n",
        "        np.save('char_input_data', data)\n",
        "        np.save('labels', labels)\n",
        "    except IOError:\n",
        "        print('Error while saving the files')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsVOUgHST5zM",
        "colab_type": "text"
      },
      "source": [
        "## Model Configuration and Train Ru\n",
        "\n",
        "- Epochs: 10\n",
        "\n",
        "- Learning Rate: 1e-3\n",
        "\n",
        "- Batch Size: 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BermO3bQTgEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "sess = tf.Session(config=config) \n",
        "backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNGThK5LTgEh",
        "colab_type": "code",
        "colab": {},
        "outputId": "17b123a5-2139-46ca-e727-cd76f4f5d0a1"
      },
      "source": [
        "dlabels = np_utils.to_categorical(labels, 26)\n",
        "\n",
        "n_epochs = 10\n",
        "ini_learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "\n",
        "model = LeNet.build(n_channels=1, \n",
        "                    rows=28, \n",
        "                    cols=28, \n",
        "                    n_classes=26, \n",
        "                    activation='relu', \n",
        "                    weights_path=None)\n",
        "\n",
        "opt = Adam(lr=ini_learning_rate, decay=ini_learning_rate / n_epochs)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "H = model.fit(x=data, \n",
        "              y=dlabels, \n",
        "              batch_size=batch_size, \n",
        "              epochs=n_epochs, \n",
        "              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20928/20928 [==============================] - 5s 242us/step - loss: 0.0257 - acc: 0.9919\n",
            "Epoch 2/10\n",
            "20928/20928 [==============================] - 3s 163us/step - loss: 0.0082 - acc: 0.9972\n",
            "Epoch 3/10\n",
            "20928/20928 [==============================] - 3s 166us/step - loss: 0.0060 - acc: 0.9980\n",
            "Epoch 4/10\n",
            "20928/20928 [==============================] - 3s 165us/step - loss: 0.0048 - acc: 0.9983\n",
            "Epoch 5/10\n",
            "20928/20928 [==============================] - 3s 164us/step - loss: 0.0041 - acc: 0.9986\n",
            "Epoch 6/10\n",
            "20928/20928 [==============================] - 3s 164us/step - loss: 0.0030 - acc: 0.9989\n",
            "Epoch 7/10\n",
            "20928/20928 [==============================] - 3s 164us/step - loss: 0.0031 - acc: 0.9989\n",
            "Epoch 8/10\n",
            "20928/20928 [==============================] - 3s 165us/step - loss: 0.0025 - acc: 0.9991\n",
            "Epoch 9/10\n",
            "20928/20928 [==============================] - 3s 165us/step - loss: 0.0025 - acc: 0.9992\n",
            "Epoch 10/10\n",
            "20928/20928 [==============================] - 3s 166us/step - loss: 0.0017 - acc: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnjO44dQUP-D",
        "colab_type": "text"
      },
      "source": [
        "## Saving the Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5otX04eSkAcI",
        "colab": {},
        "outputId": "eeb9d4be-10b9-4ff0-99b2-d8dc5ff64cc9"
      },
      "source": [
        "weights_file = 'weights_Letras.h5'\n",
        "try:\n",
        "    model.save_weights(weights_file)\n",
        "    print('File Writed as: {}'.format(weights_file))\n",
        "except IOError:\n",
        "    print('Error while saving the Model weights')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Writed as: weights_Letras.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}