{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carvalheirafc/deep_learning_stuff/blob/master/mlp/diabetes/diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Q0zh55pVSbyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Cell\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPcl2G0OSplC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "35a16382-88cd-4602-f8e4-440b96162831"
      },
      "cell_type": "code",
      "source": [
        "file_url = 'https://raw.githubusercontent.com/carvalheirafc/deep_learning_stuff/master/mlp/diabetes/diabetes_pca_result.csv'\n",
        "\n",
        "df = pd.read_csv(file_url)\n",
        "df.describe().transpose()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Component 1</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-6.693141e-17</td>\n",
              "      <td>1.711960</td>\n",
              "      <td>-5.587340</td>\n",
              "      <td>-1.027072</td>\n",
              "      <td>0.152931</td>\n",
              "      <td>1.095689</td>\n",
              "      <td>5.963579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 2</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-6.071532e-17</td>\n",
              "      <td>1.318184</td>\n",
              "      <td>-2.955806</td>\n",
              "      <td>-1.007096</td>\n",
              "      <td>-0.225966</td>\n",
              "      <td>0.959128</td>\n",
              "      <td>3.606582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 3</th>\n",
              "      <td>768.0</td>\n",
              "      <td>-3.324887e-17</td>\n",
              "      <td>1.015629</td>\n",
              "      <td>-3.203088</td>\n",
              "      <td>-0.646496</td>\n",
              "      <td>-0.103940</td>\n",
              "      <td>0.549774</td>\n",
              "      <td>4.754503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Component 4</th>\n",
              "      <td>768.0</td>\n",
              "      <td>2.349105e-18</td>\n",
              "      <td>0.966941</td>\n",
              "      <td>-2.192185</td>\n",
              "      <td>-0.664677</td>\n",
              "      <td>-0.115829</td>\n",
              "      <td>0.543242</td>\n",
              "      <td>4.125987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diagnóstico</th>\n",
              "      <td>768.0</td>\n",
              "      <td>3.489583e-01</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             count          mean       std       min       25%       50%  \\\n",
              "Component 1  768.0 -6.693141e-17  1.711960 -5.587340 -1.027072  0.152931   \n",
              "Component 2  768.0 -6.071532e-17  1.318184 -2.955806 -1.007096 -0.225966   \n",
              "Component 3  768.0 -3.324887e-17  1.015629 -3.203088 -0.646496 -0.103940   \n",
              "Component 4  768.0  2.349105e-18  0.966941 -2.192185 -0.664677 -0.115829   \n",
              "Diagnóstico  768.0  3.489583e-01  0.476951  0.000000  0.000000  0.000000   \n",
              "\n",
              "                  75%       max  \n",
              "Component 1  1.095689  5.963579  \n",
              "Component 2  0.959128  3.606582  \n",
              "Component 3  0.549774  4.754503  \n",
              "Component 4  0.543242  4.125987  \n",
              "Diagnóstico  1.000000  1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "dboMd1BEZ8_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, X_test, Y, Y_test = train_test_split(df.drop('Diagnóstico', axis=1), \n",
        "                                                  pd.to_numeric(df['Diagnóstico'], downcast='integer'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QileMbsWa3I3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "mini_batch_size = 100\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "\n",
        "\n",
        "\n",
        "n_hidden_1 = 128 # 1st layer number of features\n",
        "n_hidden_2 = 64  # 2nd layer number of features\n",
        "n_input = 4      # Number of feature\n",
        "n_classes = 2    # Number of classes to predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlz3od58bG4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(\"float\", [None, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "\n",
        "# Create model\n",
        "def multilayer_perceptron(x, weights, biases):\n",
        "    # Hidden layer with RELU activation\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    \n",
        "    # Hidden layer with RELU activation\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    \n",
        "    # Output layer with sigmoid \n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "    out_layer = tf.nn.sigmoid(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ir4QwHVIeEwn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Construct model\n",
        "pred = multilayer_perceptron(x, weights, biases)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxYT8W2IeF7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    print(\"Starting Training.\")\n",
        "\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        #avg_cost = 0.\n",
        "        # minibatch loading\n",
        "        minibatch_x = X[mini_batch_size*epoch:mini_batch_size*(epoch+1)]\n",
        "        minibatch_y = Y[mini_batch_size*epoch:mini_batch_size*(epoch+1)]\n",
        "        # Run optimization op (backprop) and cost op\n",
        "        _, c = sess.run([optimizer, cost], feed_dict={x: minibatch_x, y: minibatch_y})\n",
        "\n",
        "        # Compute average loss\n",
        "        avg_cost = c / (minibatch_x.shape[0])\n",
        "\n",
        "        # Display logs per epoch\n",
        "        if (epoch) % display_step == 0:\n",
        "          print(\"Epoch:\", '%05d' % (epoch), \"Training error=\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Test model\n",
        "    # Calculate accuracy\n",
        "    test_error = tf.nn.l2_loss(pred-y,name=\"squared_error_test_cost\")/test_set.shape[0]\n",
        "    print(\"Test Error:\", test_error.eval({x: test_set, y: test_labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}